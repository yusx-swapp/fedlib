[general]
n_clients = 100
device = cuda
communication_rounds = 100
participate_rate = 0.05


[algo]
trainer = feddp
communicator = None
sampler = random


[model]
model = resnet20
n_classes = 10

[dataset]
n_clients = ${general:n_clients}
partition = noniid-labeldir
dataset = cifar10
datadir = ./data
beta = .5
train_bs = 64 
test_bs = 128
n_worker = 32

[optimization]
lr = 0.01
optimizer = sgd
lr_scheduler = ExponentialLR
criterion = CrossEntropyLoss
local_epochs = 2

[trainer]
local_epochs = ${optimization:local_epochs}
pruning_threshold = 1e-3

[server]
n_clients = ${general:n_clients}
global_model = ${model:model}
device = ${general:device}
sampler = ${algo:sampler}
trainer = ${algo:trainer}
communicator = ${algo:communicator}

[client]
n_clients = ${general:n_clients}
device = ${general:device}
lr = ${optimization:lr}
criterion = ${optimization:criterion}
optimizer = ${optimization:optimizer}
lr_scheduler = ${optimization:lr_scheduler}
local_epochs = ${optimization:local_epochs}
