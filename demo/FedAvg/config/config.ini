[general]
n_clients = 100
device = cpu
communication_rounds = 100
participate_rate = 0.1


[algo]
trainer = feddp
communicator = None
sampler = random

[model]
model = resnet20

[dataset]
n_clients = ${general:n_clients}
partition = noniid-labeldir
dataset = cifar10
datadir = ./data
beta = .5
train_bs = 64 
test_bs = 128
n_worker = 32

[optimization]
lr = 0.01
optimizer = sgd
lr_scheduler = ExponentialLR
criterion = CrossEntropyLoss
local_epochs = 20

[trainer]
local_epochs = ${optimization:local_epochs}

[server]
n_clients = ${general:n_clients}
global_model = ${model:model}
device = ${general:device}
sampler = ${algo:sampler}
trainer = ${algo:trainer}
communicator = ${algo:communicator}

[client]
n_clients = ${general:n_clients}
device = ${general:device}
lr = ${optimization:lr}
criterion = ${optimization:criterion}
optimizer = ${optimization:optimizer}
lr_scheduler = ${optimization:lr_scheduler}
local_epochs = ${optimization:local_epochs}
