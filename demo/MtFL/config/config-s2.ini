[general]
n_clients = 100
device = cuda
communication_rounds = 500
participate_rate = 0.1
log_dir = ./logs/cifar100_specialize
ckpt_dir = ./ckpt

[algo]
trainer = feddp
communicator = None
sampler = random

[model]
model = resnet20
n_classes = 100

[dataset]
n_clients = ${general:n_clients}
partition = noniid-labeldir
dataset = cifar100
datadir = ./data
beta = .5
train_bs = 64 
test_bs = 128
n_worker = 32

[optimization]
lr = 0.1
optimizer = sgd
lr_scheduler = ExponentialLR
criterion = CrossEntropyLoss
local_epochs = 10

[trainer]
local_epochs = ${optimization:local_epochs}

[server]
n_clients = ${general:n_clients}
global_model = ${model:model}
device = ${general:device}
sampler = ${algo:sampler}
trainer = ${algo:trainer}
communicator = ${algo:communicator}
log_dir = ${general:log_dir}

[client]
n_clients = ${general:n_clients}
device = ${general:device}
lr = ${optimization:lr}
criterion = ${optimization:criterion}
optimizer = ${optimization:optimizer}
lr_scheduler = ${optimization:lr_scheduler}
local_epochs = ${optimization:local_epochs}
log_dir = ${general:log_dir}